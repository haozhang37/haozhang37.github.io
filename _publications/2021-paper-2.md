---
title: "Interpreting and Boosting Dropout from a Game-Theoretic View"
collection: publications
permalink: /publication/2021-paper-2
excerpt: 'This paper proved that the dropout can effectively reduce the significance of interactions modeled by the DNN both theoretically ad=nd experimentally. Besides, an over-fitted DNN usually encodes more interaction significance. Therefore, dropout can effectively alleviate the over-fitting problem of DNNs.'
date: 2021-05-03
venue: 'ICLR'
paperurl: 'http://haozhang37.github.io/files/ICLR2021-paper1.pdf'
citation: 'Zhang, etc. (2021). &quot;Interpreting and Boosting Dropout from a Game-Theoretic View&quot; <i>ICLR 2021</i>.'
---
This paper aims to understand and improve the utility of the dropout operation from the perspective of game-theoretic interactions. We prove that dropout can suppress the strength of interactions between input variables of deep neural networks (DNNs). The theoretic proof is also verified by various experiments. Furthermore, we find that such interactions were strongly related to the over-fitting problem in deep learning. Thus, the utility of dropout can be regarded as decreasing interactions to alleviate the significance of over-fitting. Based on this understanding, we propose an interaction loss to further improve the utility of dropout. Experimental results have shown that the interaction loss can effectively improve the utility of dropout and boost the performance of DNNs. Code is available at https://openreview.net/attachment?id=Jacdvfjicf7&name=supplementary_material.